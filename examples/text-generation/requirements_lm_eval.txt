https://github.com/EleutherAI/lm-evaluation-harness/archive/refs/tags/v0.4.2.zip
datasets==2.21.0
evaluate == 0.4.2
rouge_score == 0.1.2
accelerate < 0.34.0
pandas <= 2.2.2
