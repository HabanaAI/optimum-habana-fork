https://github.com/EleutherAI/lm-evaluation-harness/archive/0bf683b4e6a9df359b3156ba9ba8d62bdd47e0c0.zip
datasets==2.21.0
<<<<<<< HEAD
=======
evaluate == 0.4.2
rouge_score == 0.1.2
accelerate < 0.34.0
pandas <= 2.2.2
>>>>>>> 81e1cb08 ([SW-205356] Rebase to OH v1.14 (#3))
