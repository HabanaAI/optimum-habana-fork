<<<<<<< HEAD
https://github.com/EleutherAI/lm-evaluation-harness/archive/refs/tags/v0.4.7.zip
=======
lm_eval == 0.4.2
datasets==2.21.0
evaluate == 0.4.2
rouge_score == 0.1.2
accelerate < 0.34.0
pandas <= 2.2.2
>>>>>>> a2ce8e2b (Sw 190418 pr 4 (#126))
